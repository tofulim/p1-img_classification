{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/opt/ml/train')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install efficientnet_pytorch\n",
    "!pip install fastai==1.0.61\n",
    "!pip install git+https://github.com/ildoonet/pytorch-randaugment\n",
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "#from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import os,shutil,json\n",
    "import argparse\n",
    "#import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "#import natsort\n",
    "#import easydict\n",
    "import PIL\n",
    "from PIL import Image as Img\n",
    "#from skimage import io, transform\n",
    "import random\n",
    "import math\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "#import imutils\n",
    "import zipfile\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from RandAugment import RandAugment\n",
    "# from fastai import *\n",
    "# from fastai.vision import *\n",
    "import torch_optimizer as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df = pd.read_csv('train.csv')\n",
    "load_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(load_df.age))\n",
    "print(min(load_df.age))\n",
    "sns.set_theme()\n",
    "sns.distplot(load_df['age'], kde=True, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "li2 = []\n",
    "for idx, row in load_df.iterrows():\n",
    "  path = glob.glob('images/'+row['path']+'/*')\n",
    "  li.append(path)\n",
    "  li2.append([os.path.basename(x).split('.')[0][:-1] for x in path])\n",
    "flatten_li = list(np.concatenate(li).flat)\n",
    "flatten_li2 = list(np.concatenate(li2).flat)\n",
    "#print(flatten_li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = []\n",
    "for row in load_df.itertuples(index=False):\n",
    "  train_df.extend([list(row)]*7)\n",
    "train_df = pd.DataFrame(train_df, columns=load_df.columns)\n",
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['path']=flatten_li\n",
    "train_df['mask']=flatten_li2\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['id']\n",
    "del train_df['race']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age2idx(age):\n",
    "  if age < 30:\n",
    "    return 0\n",
    "  elif age >=60:\n",
    "    return 2\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = train_df['gender'].unique()\n",
    "#age = train_df['age'].unique()\n",
    "mask = train_df['mask'].unique()\n",
    "#print(gender, age, mask)\n",
    "gender2idx = {o:i for i,o in enumerate(gender)}\n",
    "#age2idx = {o:i for i,o in enumerate(age)}\n",
    "mask2idx = {o:i for i,o in enumerate(mask)}\n",
    "\n",
    "train_df['gender'] = train_df['gender'].apply(lambda x: gender2idx[x])\n",
    "train_df['age'] = train_df['age'].apply(lambda x: age2idx(x))\n",
    "train_df['mask'] = train_df['mask'].apply(lambda x: mask2idx[x])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.distplot(train_df['mask'], kde=True, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_df = []\n",
    "for row in train_df.itertuples(index=False):\n",
    "  if row.mask != 0:\n",
    "    append_df.extend([list(row)]*1)\n",
    "append_df = pd.DataFrame(append_df, columns=train_df.columns)\n",
    "append_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.distplot(train_df['mask'], kde=True, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tf):\n",
    "        self.path = list(df['path'])\n",
    "        self.gender = list(df['gender'])\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            # transforms.Resize((224, 224)),\n",
    "            transforms.CenterCrop((350,256)),            \n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        if tf:\n",
    "            self.transform.transforms.insert(0,RandAugment(2,9))\n",
    "\n",
    "    def __len__(self): return len(self.path)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #dealing with the image\n",
    "        im = PIL.Image.open(self.path[idx]).convert('RGB')\n",
    "        im = self.transform(im)\n",
    "\n",
    "\n",
    "        #dealing with the labels\n",
    "        gender = torch.tensor(int(self.gender[idx]), dtype=torch.int64)\n",
    "        sample = {\n",
    "            'image':im,\n",
    "            'label':gender\n",
    "        }\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelResnext(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelResnext, self).__init__()\n",
    "        self.resnext = models.resnext101_32x8d(pretrained=True)\n",
    "        #self.resnext = models.resnext50_32x4d(pretrained=True)\n",
    "        self.drop = nn.Dropout(p=0.7)\n",
    "        self.FC = nn.Linear(1000, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        # x = F.silu(self.conv2d(x))\n",
    "\n",
    "        # efficientnet b7\n",
    "        # 원래는 efficientnet과 동일하게 swish를 넣으려고 했으나\n",
    "        # 별 차이 없는 듯 해서 그냥 silu 적용\n",
    "        x = F.gelu(self.resnext(x))\n",
    "\n",
    "        x = self.drop(x)\n",
    "        x = self.FC(x)\n",
    "        return x\n",
    "model = MultiLabelResnext()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(log_pred, y_true):\n",
    "    y_pred = np.argmax(log_pred)\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\n",
    "for fold_index, (trn_idx, val_idx) in enumerate(kfold.split(train_df),1):\n",
    "    print(f'[fold: {fold_index}]')\n",
    "    \n",
    "    # cuda cache 초기화\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #train fold, validation fold 분할\n",
    "    train_answer = train_df.iloc[trn_idx]\n",
    "    test_answer  = train_df.iloc[val_idx]\n",
    "    \n",
    "    #Dataset 정의\n",
    "    train_dataset = MultiTaskDataset(train_answer, tf=True)\n",
    "    valid_dataset = MultiTaskDataset(test_answer, tf=False)\n",
    "    \n",
    "    #DataLoader 정의\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = 64,\n",
    "        shuffle = True,\n",
    "        num_workers = 2\n",
    "    )\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size = 32,\n",
    "        shuffle = False,\n",
    "        num_workers = 2\n",
    "    )\n",
    "\n",
    "    # 모델 선언\n",
    "    #model = MultiLabelEfficientnet()\n",
    "    model = MultiLabelResnext()\n",
    "    model.to(device)# gpu에 모델 할당\n",
    "    \n",
    "    # 훈련 옵션 설정\n",
    "    #optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "    optimizer = optim.RAdam(model.parameters(), lr = 1e-3)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                step_size = 5,\n",
    "                                                gamma = 0.9)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 훈련 시작\n",
    "    valid_acc_max = 0\n",
    "    valid_loss_min = float(\"inf\")\n",
    "    for epoch in range(30):\n",
    "        # 1개 epoch 훈련\n",
    "        train_acc_list = []\n",
    "        train_loss_list = []\n",
    "        with tqdm(train_data_loader,#train_data_loader를 iterative하게 반환\n",
    "                total=train_data_loader.__len__(), # train_data_loader의 크기\n",
    "                unit=\"batch\") as train_bar:# 한번 반환하는 sample의 단위는 \"batch\"\n",
    "            for sample in train_bar:\n",
    "                train_bar.set_description(f\"Train Epoch {epoch}\")\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                images, labels = sample['image'], sample['label']\n",
    "                # tensor를 gpu에 올리기 \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "            \n",
    "                # 모델의 dropoupt, batchnormalization를 train 모드로 설정\n",
    "                model.train()\n",
    "                # .forward()에서 중간 노드의 gradient를 계산\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    # 모델 예측\n",
    "                    probs  = model(images)\n",
    "                    # loss 계산\n",
    "                    loss = criterion(probs, labels)\n",
    "                    # 중간 노드의 gradient로\n",
    "                    # backpropagation을 적용하여\n",
    "                    # gradient 계산\n",
    "                    loss.backward()\n",
    "                    # weight 갱신\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # train accuracy 계산\n",
    "                    probs  = probs.cpu().detach().numpy()\n",
    "                    labels = labels.cpu().detach().numpy()\n",
    "                    #preds = probs > 0.5\n",
    "                    batch_acc = accuracy(probs, labels)\n",
    "                    train_acc_list.append(batch_acc)\n",
    "                    train_acc = np.mean(train_acc_list)\n",
    "                    train_loss_list.append(loss.item())\n",
    "                    train_loss = np.mean(train_loss_list)\n",
    "                # 현재 progress bar에 현재 미니배치의 loss 결과 출력\n",
    "                train_bar.set_postfix(train_loss= train_loss,\n",
    "                                      train_acc = train_acc)\n",
    "                \n",
    "        # 1개 epoch학습 후 Validation 점수 계산\n",
    "        valid_acc_list = []\n",
    "        valid_loss_list = []\n",
    "        with tqdm(valid_data_loader,\n",
    "                total=valid_data_loader.__len__(),\n",
    "                unit=\"batch\") as valid_bar:\n",
    "            for sample in valid_bar:\n",
    "                valid_bar.set_description(f\"Valid Epoch {epoch}\")\n",
    "                optimizer.zero_grad()\n",
    "                images, labels = sample['image'], sample['label']\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # 모델의 dropoupt, batchnormalization를 eval모드로 설정\n",
    "                model.eval()\n",
    "                # .forward()에서 중간 노드의 gradient를 계산\n",
    "                with torch.no_grad():\n",
    "                    # validation loss만을 계산\n",
    "                    probs  = model(images)\n",
    "                    valid_loss = criterion(probs, labels)\n",
    "\n",
    "                    # train accuracy 계산\n",
    "                    probs  = probs.cpu().detach().numpy()\n",
    "                    labels = labels.cpu().detach().numpy()\n",
    "#                     preds = probs > 0.5\n",
    "                    batch_acc = accuracy(probs, labels)\n",
    "                    valid_acc_list.append(batch_acc)\n",
    "                    valid_loss_list.append(valid_loss.item())\n",
    "                valid_acc = np.mean(valid_acc_list)\n",
    "                valid_loss = np.mean(valid_loss_list)\n",
    "                valid_bar.set_postfix(valid_loss = valid_loss,\n",
    "                                      valid_acc = valid_acc)\n",
    "                \n",
    "        # Learning rate 조절\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # 모델 저장\n",
    "        if valid_loss_min > valid_loss:\n",
    "            valid_loss_min = valid_loss\n",
    "            best_model = model\n",
    "            \n",
    "    # 폴드별로 가장 좋은 모델 저장\n",
    "    MODEL = \"resnext101_gender\"\n",
    "    # 모델을 저장할 구글 드라이브 경로\n",
    "    path = \"/opt/ml/pstage_1/\"\n",
    "    torch.save(best_model, f'{path}{MODEL}_{fold_index}_{valid_loss:2.4f}.pth')\n",
    "    best_models.append(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-virgin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-folks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
