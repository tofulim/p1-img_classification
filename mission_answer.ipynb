{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#!apt-get -y install libgl1-mesa-glx\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import time\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    data_dir = '/opt/ml/input/data/train'\n",
    "    img_dir = f'{data_dir}/images'\n",
    "    df_path = f'{data_dir}/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2class = ['incorrect_mask', 'mask1', 'mask2', 'mask3',\n",
    "             'mask4', 'mask5', 'normal']\n",
    "class2num = {k: v for v, k in enumerate(num2class)}\n",
    "\n",
    "df = pd.read_csv(cfg.df_path)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df.age>=60) & (df.gender==\"male\")]  #60대이상 남자는 83 여자는 109명\n",
    "# #df[df.age>=60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(img_dir, img_id):\n",
    "    \"\"\"\n",
    "    학습 데이터셋 이미지 폴더에는 여러 하위폴더로 구성되고, 이 하위폴더들에는 각 사람의 사진들이 들어가있습니다. 하위폴더에 속한 이미지의 확장자를 구하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        img_dir: 학습 데이터셋 이미지 폴더 경로 \n",
    "        img_id: 학습 데이터셋 하위폴더 이름\n",
    "\n",
    "    Returns:\n",
    "        ext: 이미지의 확장자\n",
    "    \"\"\"\n",
    "    filename = os.listdir(os.path.join(img_dir, img_id))[0] #매개변수 path의 모든 디렉터리와 파일을 배열로 받는다. 그중 0번째 idx를 파일이름으로\n",
    "    ext = os.path.splitext(filename)[-1].lower() #확장자를 뽑으므로 -1번째\n",
    "    return ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_stats(img_dir, img_ids):\n",
    "    \"\"\"\n",
    "    데이터셋에 있는 이미지들의 크기와 RGB 평균 및 표준편차를 수집하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        img_dir: 학습 데이터셋 이미지 폴더 경로 \n",
    "        img_ids: 학습 데이터셋 하위폴더 이름들, 각 사람들 ex) 000002_female~\n",
    "\n",
    "    Returns:\n",
    "        img_info: 이미지들의 정보 (크기, 평균, 표준편차)\n",
    "    \"\"\"\n",
    "    img_info = dict(heights=[], widths=[], means=[], stds=[])\n",
    "    for img_id in tqdm(img_ids):\n",
    "        for path in glob(os.path.join(img_dir, img_id, '*')): #glob로 그 사람폴더내 모든 사진을 배열로 가져옴\n",
    "            img = np.array(Image.open(path)) #path는 사진 하나를 의미, 그것을 3차원 텐서로 RGB표현함\n",
    "            h, w, _ = img.shape\n",
    "            img_info['heights'].append(h)\n",
    "            img_info['widths'].append(w)\n",
    "            img_info['means'].append(img.mean(axis=(0,1))) #채널별로 평균과 표준편차를 구한다\n",
    "            img_info['stds'].append(img.std(axis=(0,1)))\n",
    "    return img_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_info = get_img_stats(cfg.img_dir, df.path.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Total number of people is {len(df)}')\n",
    "# print(f'Total number of images is {len(df) * 7}')\n",
    "# print(f'Minimum height for dataset is {np.min(img_info[\"heights\"])}')\n",
    "# print(f'Maximum height for dataset is {np.max(img_info[\"heights\"])}')\n",
    "# print(f'Average height for dataset is {int(np.mean(img_info[\"heights\"]))}')\n",
    "# print(f'Minimum width for dataset is {np.min(img_info[\"widths\"])}')\n",
    "# print(f'Maximum width for dataset is {np.max(img_info[\"widths\"])}')\n",
    "# print(f'Average width for dataset is {int(np.mean(img_info[\"widths\"]))}')\n",
    "\n",
    "# print(f'RGB Mean: {np.mean(img_info[\"means\"], axis=0) / 255.}')\n",
    "# print(f'RGB Standard Deviation: {np.mean(img_info[\"stds\"], axis=0) / 255.}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 4.5)) \n",
    "# ax = sns.countplot(x = 'gender', data = df, palette=[\"#55967e\", \"#263959\"])\n",
    "\n",
    "# plt.xticks( np.arange(2), ['female', 'male'] )\n",
    "# plt.title('Sex Ratio',fontsize= 14)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('Number of images')\n",
    "\n",
    "# counts = df['gender'].value_counts()\n",
    "# counts_pct = [f'{elem * 100:.2f}%' for elem in counts / counts.sum()]\n",
    "# for i, v in enumerate(counts_pct):\n",
    "#     ax.text(i, 0, v, horizontalalignment = 'center', size = 14, color = 'w', fontweight = 'bold')\n",
    "    \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(df, x=\"age\", hue=\"gender\", stat=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_id = df.iloc[500].path\n",
    "# ext = get_ext(cfg.img_dir, img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.subplot(111)\n",
    "\n",
    "# for class_id in num2class:\n",
    "#     img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, class_id+ext)).convert('L'))\n",
    "#     #print(img)\n",
    "#     histogram, bin_edges = np.histogram(img, bins=256, range=(0, 255))\n",
    "#     sns.lineplot(data=histogram)\n",
    "\n",
    "# plt.legend(num2class)\n",
    "# plt.title('Class Grayscale Histogram Plot', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_images(img_dir, img_id):\n",
    "    \"\"\"\n",
    "    마스크 미착용 이미지를 시각화하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        img_dir: 학습 데이터셋 이미지 폴더 경로 \n",
    "        img_id: 학습 데이터셋 하위폴더 이름\n",
    "    \"\"\"\n",
    "    ext = get_ext(img_dir, img_id)\n",
    "    img = np.array(Image.open(os.path.join(img_dir, img_id, 'normal' + ext)))\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_raw_images(cfg.img_dir, img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import transforms\n",
    "# from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, img_paths, transform):\n",
    "#         self.img_paths = glob(os.path.join(cfg.img_dir, img_paths, '*'))\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image = Image.open(self.img_paths[index])\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img_id='000001_female_Asian_45'\n",
    "# img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, 'normal' + ext)))\n",
    "# #print(img)\n",
    "# #plt.imshow(img)\n",
    "# # tsfm=transforms.Compose([\n",
    "# #      transforms.ToPILImage(),\n",
    "# #      transforms.ToTensor(),\n",
    "# #      transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "# # ])\n",
    "# # img=tsfm(img)\n",
    "# transform = transforms.Compose([\n",
    "#     # BILINEAR(2),\n",
    "#     ToTensor(),\n",
    "#     Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "#     transforms.ToPILImage(),\n",
    "# ])\n",
    "# dataset = TestDataset(img_id, transform)\n",
    "# #print(dataset.img_paths)\n",
    "# #/opt/ml/input/data/train/images/000001_female_Asian_45/normal.jpg\n",
    "# #print(len(dataset))\n",
    "# #plt.imshow(dataset[0])\n",
    "# plt.imshow(dataset[1])\n",
    "# #plt.imshow(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = (0.56019358 ,0.52410121, 0.501457), (0.23318603, 0.24300033 ,0.24567522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_transforms(need=('train', 'val'), img_size=(512, 384), mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "    \"\"\"\n",
    "    train 혹은 validation의 augmentation 함수를 정의합니다. train은 데이터에 많은 변형을 주어야하지만, validation에는 최소한의 전처리만 주어져야합니다.\n",
    "    \n",
    "    Args:\n",
    "        need: 'train', 혹은 'val' 혹은 둘 다에 대한 augmentation 함수를 얻을 건지에 대한 옵션입니다.\n",
    "        img_size: Augmentation 이후 얻을 이미지 사이즈입니다.\n",
    "        mean: 이미지를 Normalize할 때 사용될 RGB 평균값입니다.\n",
    "        std: 이미지를 Normalize할 때 사용될 RGB 표준편차입니다.\n",
    "\n",
    "    Returns:\n",
    "        transformations: Augmentation 함수들이 저장된 dictionary 입니다. transformations['train']은 train 데이터에 대한 augmentation 함수가 있습니다.\n",
    "    \"\"\"\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            GaussNoise(p=0.5),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = Compose([\n",
    "            Resize(img_size[0], img_size[1]),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLabels:\n",
    "    mask = 0\n",
    "    incorrect = 1\n",
    "    normal = 2\n",
    "\n",
    "class GenderLabels:\n",
    "    male = 0\n",
    "    female = 1\n",
    "\n",
    "class AgeGroup:\n",
    "    map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 60 else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1.jpg\": MaskLabels.mask,\n",
    "        \"mask2.jpg\": MaskLabels.mask,\n",
    "        \"mask3.jpg\": MaskLabels.mask,\n",
    "        \"mask4.jpg\": MaskLabels.mask,\n",
    "        \"mask5.jpg\": MaskLabels.mask,\n",
    "        \"incorrect_mask.jpg\": MaskLabels.incorrect,\n",
    "        \"normal.jpg\": MaskLabels.normal\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "    \n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            for file_name, label in self._file_names.items():\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                if os.path.exists(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(label)\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = getattr(GenderLabels, gender)\n",
    "                    age_label = AgeGroup.map_label(age)\n",
    "\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n",
    "transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = MaskDataset(\n",
    "    img_dir=cfg.img_dir\n",
    ")\n",
    "\n",
    "# train dataset과 validation dataset을 8:2 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataloader은 데이터를 섞어주어야 합니다. (shuffle=True)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=512,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=512,\n",
    "    num_workers=0,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.cuda.set_device(0)\n",
    "# images, labels = next(iter(train_loader))\n",
    "# images=images.to(device)\n",
    "# labels=labels.to(device)\n",
    "# print(f'images shape: {images.shape}')\n",
    "# print(f'labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Augmentation으로 이미지를 Normalize했기 때문에, 역으로 다시 Normalize 해주어야합니다.\n",
    "# inv_normalize = transforms.Normalize(\n",
    "#     mean=[-m / s for m, s in zip(mean, std)],\n",
    "#     std=[1 / s for s in std]\n",
    "# )\n",
    "\n",
    "# n_rows, n_cols = 4, 3\n",
    "\n",
    "# fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(16, 24))\n",
    "# for i in range(n_rows*n_cols):\n",
    "#     axes[i%n_rows][i//(n_cols+1)].imshow(inv_normalize(images[i]).permute(1, 2, 0))\n",
    "#     axes[i%n_rows][i//(n_cols+1)].set_title(f'Label: {labels[i]}', color='r')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n",
    "#         self.bn1 = nn.BatchNorm2d(num_features=3)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. using named_parameters()\n",
    "# for param, weight in model.named_parameters():\n",
    "#     print(f\"{param:20} - size: {weight.size()}\")\n",
    "#     print(weight)\n",
    "#     print(\"-\" * 100)\n",
    "#     print()\n",
    "#model.state_dict(), model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. directly access with member variable\n",
    "# print(model.conv1.weight)\n",
    "# print(model.conv1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##학습된 모델 저장하기\n",
    "# save_folder = \"/opt/ml/code/save_model\"\n",
    "# save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n",
    "# os.makedirs(save_folder, exist_ok=True)  \n",
    "\n",
    "# torch.save(model.state_dict(), save_path)\n",
    "# print(f\"Model saving success at {save_path}\")\n",
    "# print(f\"Saved models : {os.listdir(save_folder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = Model()\n",
    "# new_model.load_state_dict(torch.load(save_path))\n",
    "# print(f\"Model loading success from {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n",
    "#     is_equal = torch.equal(trained_weight, saved_weight)\n",
    "#     print(f\"parameter {name:15} from trained model and loaded model is equal? -> {is_equal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "# device=torch.device('cuda')\n",
    "model = resnet50(pretrained=True)\n",
    "num_classes = 18\n",
    "model.fc = nn.Linear(2048,18)\n",
    "# Freeze except fc parts\n",
    "model.conv1.requires_grad_(False)\n",
    "model.bn1.requires_grad_(False)\n",
    "model.layer1.requires_grad_(False)\n",
    "model.layer1.requires_grad_(False)\n",
    "model.layer2.requires_grad_(False)\n",
    "model.layer3.requires_grad_(False)\n",
    "model.layer4.requires_grad_(False)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:20} required gradient? -> {weight.requires_grad}\")\n",
    "model.cuda()\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Initialize all weights using xavier uniform. \n",
    "    For more weight initialization methods, check https://pytorch.org/docs/stable/nn.init.html\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc.weight.data.normal_(0,0.01)\n",
    "model.fc.weight.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(),lr=3e-4)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss=0.0\n",
    "    for i,data in tqdm(enumerate(train_loader,0)):\n",
    "        inputs,labels=data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "#         if i%256==255:\n",
    "#             print('[%d, %5d] loss : %.3f' % (epoch+1,i+1,running_loss/2000))\n",
    "#             running_loss=0.0\n",
    "        print('[%d, %5d] loss : %.3f' % (epoch+1,i+1,running_loss))\n",
    "        running_loss=0.0\n",
    "print(\"finished training\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##학습된 모델 저장하기\n",
    "save_folder = \"/opt/ml/code/save_model\"\n",
    "save_path = os.path.join(save_folder, \"best2.pth\")   # ./runs/best.pth\n",
    "os.makedirs(save_folder, exist_ok=True)  \n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saving success at {save_path}\")\n",
    "print(f\"Saved models : {os.listdir(save_folder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#         print(\"Calculating validation results...\")\n",
    "#         model.eval()\n",
    "#         val_loss_items = []\n",
    "#         val_acc_items = []\n",
    "#         for val_batch in val_loader:\n",
    "#             inputs, labels = val_batch\n",
    "#             inputs = inputs.cuda()\n",
    "#             labels = labels.cuda()\n",
    "\n",
    "#             outs = model(inputs)\n",
    "#             preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "#             loss_item = criterion(outs, labels).item()\n",
    "#             acc_item = (labels == preds).sum().item()\n",
    "#             val_loss_items.append(loss_item)\n",
    "#             val_acc_items.append(acc_item)\n",
    "\n",
    "#         val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "#         val_acc = np.sum(val_acc_items) / len(val_loader)\n",
    "#         print(\n",
    "#             f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir='/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=mean, std=std),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "model_root = '/opt/ml/code/save_model/best1.pth'\n",
    "from torchvision.models import resnet50\n",
    "model = resnet50(pretrained=True)\n",
    "model.to(device)\n",
    "num_classes = 18\n",
    "model.fc = nn.Linear(2048,18)\n",
    "model.load_state_dict(torch.load(model_root))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.cuda()\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission3.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
