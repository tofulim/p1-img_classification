{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "following-elite",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "#추가\n",
    "\n",
    "# import wheel\n",
    "# import torchvision\n",
    "# from torch.autograd import Variable\n",
    "# from torch.autograd import Function\n",
    "# import cv2\n",
    "# import functools\n",
    "# import urllib\n",
    "# import numpy as np\n",
    "# import sys\n",
    "# import math\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# from glob import glob\n",
    "# from scipy.ndimage.filters import gaussian_filter\n",
    "# from IPython.display import clear_output, Image, display, HTML\n",
    "# from google.protobuf import text_format\n",
    "# from io import StringIO\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "# plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-shakespeare",
   "metadata": {},
   "source": [
    "## 1. Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyModel(nn.Module):\n",
    "#     def __init__(self, num_classes: int = 1000):\n",
    "#         super(MyModel, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#         )\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(32, num_classes),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         x = self.features(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "class VGG11BackBone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG11BackBone, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Convolution Feature Extraction Part\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3_1   = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn3_2   = nn.BatchNorm2d(256)\n",
    "        self.pool3   = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4_1   = nn.BatchNorm2d(512)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn4_2   = nn.BatchNorm2d(512)\n",
    "        self.pool4   = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn5_1   = nn.BatchNorm2d(512)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn5_2   = nn.BatchNorm2d(512)\n",
    "        self.pool5   = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.bn3_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.bn3_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.bn4_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.bn4_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.bn5_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = self.bn5_2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class VGG11Classification(nn.Module):\n",
    "  def __init__(self, num_classes = 18):\n",
    "    super(VGG11Classification, self).__init__()\n",
    "\n",
    "    self.backbone = VGG11BackBone()\n",
    "    self.gap      = nn.AdaptiveAvgPool2d(1)\n",
    "    self.fc_out   = nn.Linear(512, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.backbone(x)\n",
    "    x = self.backbone.pool5(x)\n",
    "\n",
    "    x = self.gap(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc_out(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-toilet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-fellowship",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model_root = '/opt/ml/input/data/model_pretrained.pth'\n",
    "\n",
    "model = VGG11Classification(num_classes = 18)\n",
    "model.load_state_dict(torch.load(model_root))\n",
    "# model = MyModel(num_classes=18).to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission2.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-pressure",
   "metadata": {},
   "source": [
    "## 2. Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-endorsement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
